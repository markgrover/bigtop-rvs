--- pom.xml	2012-01-16 07:03:35.000000000 -0800
+++ pom.xml	2012-02-17 09:46:32.506195389 -0800
@@ -1788,6 +1788,13 @@
           <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
           <version>${hadoop.version}</version>
           <optional>true</optional>
+          <scope>test</scope>
+        </dependency>
+        <dependency>
+          <groupId>org.apache.hadoop</groupId>
+          <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
+          <version>${hadoop.version}</version>
+          <optional>true</optional>
           <type>test-jar</type>
           <scope>test</scope>
         </dependency>
--- src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java	2012-01-16 07:03:40.000000000 -0800
+++ src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLog.java	2012-02-17 09:46:32.466194915 -0800
@@ -423,7 +423,7 @@
     if (os != null) {
       try {
         m = os.getWrappedStream().getClass().
-          getMethod("getNumCurrentReplicas", new Class<?> []{});
+          getDeclaredMethod("getNumCurrentReplicas", new Class<?> []{});
         m.setAccessible(true);
       } catch (NoSuchMethodException e) {
         // Thrown if getNumCurrentReplicas() function isn't available
@@ -438,7 +438,7 @@
       LOG.info("Using getNumCurrentReplicas--HDFS-826");
     } else {
       LOG.info("getNumCurrentReplicas--HDFS-826 not available; hdfs_out=" +
-        os + ", exception=" + exception.getMessage());
+        os, exception);
     }
     return m;
   }
--- src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java	2012-01-16 07:03:36.000000000 -0800
+++ src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java	2012-02-17 09:46:32.446194449 -0800
@@ -1164,6 +1164,8 @@
     LOG.info("Mini mapreduce cluster started");
     c.set("mapred.job.tracker",
         mrCluster.createJobConf().get("mapred.job.tracker"));
+    /* this for mrv2 support */
+    conf.set("mapreduce.framework.name", "yarn");
   }
 
   /**
--- src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java	2012-01-16 07:03:37.000000000 -0800
+++ src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java	2012-02-17 09:46:32.436195465 -0800
@@ -335,13 +335,18 @@
     // We start 3 servers and then stop 2 to avoid a directory naming conflict
     //  when we stop/start a namenode later, as mentioned in HBASE-5163
     List<DataNode> existingNodes = dfsCluster.getDataNodes();
-    dfsCluster
-        .startDataNodes(TEST_UTIL.getConfiguration(), 3, true, null, null);
-    for (DataNode dn: existingNodes){
-      dfsCluster.stopDataNode( dn.dnRegistration.getName() );
+    int numDataNodes = 3;
+    dfsCluster.startDataNodes(TEST_UTIL.getConfiguration(), numDataNodes, true,
+        null, null);
+    List<DataNode> allNodes = dfsCluster.getDataNodes();
+    for (int i = allNodes.size()-1; i >= 0; i--) {
+      if (existingNodes.contains(allNodes.get(i))) {
+        dfsCluster.stopDataNode( i );
+      }
     }
 
-    assertTrue(
+    assertTrue("DataNodes " + dfsCluster.getDataNodes().size() +
+        " default replication " + fs.getDefaultReplication(),
       dfsCluster.getDataNodes().size() >= fs.getDefaultReplication() + 1);
 
     writeData(table, 2);
